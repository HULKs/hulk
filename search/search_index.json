{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#overview","title":"Overview","text":"<p>Welcome to the documentation for the HULKs software. The section titles can be found in the bar at the top, inside a section the chapters will be listed on the left. Longer chapters will provide a table of contents on the right.</p> <p>TODO: the following paragraph needs to be reformulated</p> <p>We plan to release a \"final\" code release each year after RoboCup for which the documentation should be complete and correct. In addition to the yearly code release, we publish a weekly snapshot on a separate branch. Due to the frequent changes in the weekly branch, the documentation can be outdated at times.</p> <p>All our code is released under the terms of the GNU General Public License v3.</p> <p>If you have questions that are not answered here, please file issues in our GitHub issue tracker so we can fix the documentation for everyone. As our team has limited resources, we don't expect to be able to give much in-depth support individually.</p>"},{"location":"#documentation-status","title":"Documentation Status","text":"Section Status Setup Incomplete Framework Incomplete, partially outdated Tooling Incomplete Operating System Missing Robotics Missing Workflow Missing"},{"location":"framework/communication/","title":"Communication","text":"<p>Communication is the subcomponent in the framework that makes the Cyclers introspectable to the outside world. Whereas the cyclers are required to run in a realtime manner, communication does not have this requirement. Since it deals with external I/O and applications connected over the network which may influence the performance and responsiveness, it serves all its features in a best effort way and therefore decouples this influence from the cyclers.</p> <p>At a high-level, communication allows applications connected from outside to...</p> <ul> <li>subscribe to databases from cyclers and receive selected fields from them (database_subscription_manager)</li> <li>subscribe to configuration parameters, receive changed ones, and update them (parameter_modificator)</li> </ul>"},{"location":"framework/communication/#asynchronous-channels-and-tasks","title":"Asynchronous Channels and Tasks","text":"<p>Since communication deals with I/O and is idle most of the time waiting for I/O, it is implemented as an asynchronous subcomponent (using the Tokio Rust crate) with the message passing paradigm. The parts of communication are executed as asynchronous tasks which are then connected together via message passing channels. The following drawing shows all tasks in communication as square boxes (except the cycler threads, but they can be seen as task-like as well).</p> <p></p> <p>Solid connections represent dataflow implemented with channels and dashed connections show the startup behavior of the tasks.</p>"},{"location":"framework/communication/#task-spawning-and-connection-management","title":"Task Spawning and Connection Management","text":"<p>The entrypoint is the Communication Runtime which is a thread running a Tokio asynchronous runtime. This thread is started from the framework's Runtime, similar to the cycler threads. The communication runtime spawns three tasks and connects them with channels. The accepter task listens for new connections on the socket and spawns a new connection task for each incoming connection. The connection task is a short-lived task which splits the connection socket into a sending and receiving half and spawns a long-lived task for each half, the sender and receiver tasks. This splitting allows the sender and receiver to act as multiplexing/demultiplexing tasks if viewed in terms of their channel attachment points. The receiver interprets incoming messages from the socket and forwards them to the appropriate processing task (e.g. database_subscription_manager or parameter_modificator). The sender gathers all messages from the connected tasks and sends them to the connected socket.</p>"},{"location":"framework/communication/#database-subscriptions","title":"Database Subscriptions","text":"<p>Communication allows connected clients to subscribe to databases from cyclers and receive selected fields from them. Subscriptions are managed in the database_subscription_manager task. The receiver task forwards (un-)subscription requests from the client to the database_subscription_manager. If a connection is closed, the receiver sends an <code>UnsubscribeEverything</code> request to the manager task. Since all interaction between the tasks happens via channels, in some requests it is necessary to include other channel endpoints (e.g. for transferring back results). Subscriptions always contain a cycler, output type, and data path. If cyclers complete their execution of all modules, the written database is completed and freed. Afterwards, the cycler notifies a <code>Notify</code> which is shared between the cycler and the database_subscription_manager task in communication. This allows the manager task to wait for newly available databases from any cycler. When a new database is ready, the manager task iterates all relevant subscriptions to extract subscribed types and images to construct messages for the subscribed clients. Additional outputs that have been subscribed are sent to the cycler s.t. it can instruct modules to generate the additional outputs.</p>"},{"location":"framework/communication/#parameter-subscriptions-updates","title":"Parameter Subscriptions &amp; Updates","text":"<p>Communication allows connected clients to subscribe to configuration parameters, receive changed ones, and update them. Similar to database subscriptions, parameter subscriptions are processed from the receiver task.</p> <p>TODO:</p> <ul> <li>(WebSocket) Protocol/(JSON) (De-)Serialization<ul> <li>Acceptor</li> <li>Connection Setup (WebSocket handshake)</li> <li>Sender/Receiver</li> <li>Message Format</li> </ul> </li> </ul>"},{"location":"framework/cyclers/","title":"Cyclers","text":"<p>A cycler in the HULKs robotic control software is a subcomponent that cycles nodes. The name \"cycler\" comes from the characteristic that it contains a loop that iterates over incoming data and produces output data in each iteration. The cyclers call their internal <code>cycle()</code> function in each iteration. This <code>cycle()</code> function consists of three steps:</p> <ol> <li>Setup: Wait for new data and prepare cycle</li> <li>Process: Run nodes on the received data</li> <li>Finalize: E.g. send actuator commands or store data before starting the next cycle</li> </ol> <p>Multiple cyclers exist in the whole robotic control software. One of the main tasks of the framework is to allow cyclers to communicate with each other. For example, in the setup step, data from other cyclers and communication is gathered. In addition, during the finalize step, data produced in the process step of this cycle may need to be communicated back to other cyclers.</p> <p>Cyclers are separated into realtime cyclers, e.g. the control cycler, and perception cyclers, e.g. the vision cycler.</p>"},{"location":"framework/cyclers/#realtime-cyclers","title":"Realtime Cyclers","text":"<p>A realtime cycler is a central cycler that has realtime characteristics. It reacts to external events from the environment, then integrates data from the perception cyclers, and produces some output in the end. One example is the control cycler which runs in realtime synchronized to the LoLA interval (83 Hz). It receives sensor data from HULA/LoLA via the Hardware Interface and produces actuator output which is sent back to HULA/LoLA. The control cycler integrates data from all other perception cyclers (e.g. audio, SPL network, vision) in its filtering pipeline. Features for assisting in data integration in the filtering pipeline are explained in Filtering. The control cycler contains all robotics code that needs to be evaluated in each realtime cycle. In other words, all nodes that are required to generate new outputs are included. Nodes that can be excluded or need to much computation, for example the vision pipeline, are executed to their own perception cyclers.</p>"},{"location":"framework/cyclers/#perception-cyclers","title":"Perception Cyclers","text":"<p>Beside the central realtime cyclers, multiple perception cyclers exist which perceive data from the outside world and preprocess it. The outputs of each cycle are integrated in realtime cyclers to be respected for its realtime outputs. Since perception cyclers run in parallel to realtime cyclers - and they are able to integrate historic data - perception cyclers may run at different cycle intervals. Perception cyclers normally wait on an event triggered from outside e.g. a new camera image or network message. The beginning of the processing is announced to realtime cyclers in the setup step. In addition, perception cyclers acquire requested data from the realtime cyclers. The perception cycle's output data is sent to the realtime cyclers at the end of the cycle in the finalize step. More information about the interleaving of perceived data can be found in Filtering. The following perception cyclers exist:</p> <ul> <li>audio: Receives audio data from the Hardware Interface e.g. from NAO microphones</li> <li>spl_network: Waits for incoming network messages or outgoing message sending requests from other cyclers.   Each cycle either preprocesses the incoming messages (e.g. by parsing) or sends the outgoing messages to the network.</li> <li>vision_top: Receives top camera images from the Hardware Interface and processes them to extract several features.</li> <li>vision_bottom: Similar to vision_top but receives camera images from the bottom camera.</li> </ul>"},{"location":"framework/databases_and_types/","title":"Databases &amp; Types","text":"<p>Modules may produce non-standard types. These specific types are defined in the directory <code>crates/types</code>.</p> <p>A database contains all outputs of the nodes within a cycle. For each cycler one database exists where it stores the outputs. It is represented by a Rust struct. If a node requires an input, a reference to the field in the database struct is given to the node. The fields in the databases may contain Rust's <code>Option</code> types of the node types. Often, an <code>Option::Some</code> represents that the field has been generated and can be used. <code>Option::None</code> can be interpreted as a soft-error that the producing node was not able to generate the output in this cycle. This can happen for example if the camera projection is not valid for a cycle. But, databases can also contain plain Rust types, for example if the node always produces some output. More information about the <code>Option</code> encoded types is explained in Error Handling and Macros.</p> <p>TODO: Elaborate</p> <p>TODO: Explain (de-)serialization of types (Example code!)</p>"},{"location":"framework/directory_structure/","title":"Directory Structure","text":"<p>The main code repository represents a monorepo containing many parts of the robotic control software and several tools. The directory structure is organized as follows, only touching parts relevant for the framework:</p> <ul> <li><code>crates/</code>: Contains several crates relevant to the framework, beside other crates for the robotics domain and tooling<ul> <li><code>code_generation/</code>: Once the source code is analyzed, this crate will generate all necessary code to execute all cyclers and nodes</li> <li><code>communication/</code>: The Communication server (for the framework) and client (for debug tooling)</li> <li><code>context_attribute/</code>: Contains the proc-macro <code>#[context]</code> used in our nodes to augment and prepare them for the execution in the framework</li> <li><code>framework/</code>: Some basic building blocks (future queue and multiple buffers) and other framework types</li> <li><code>parameters/</code>: Functionality for de/serializing a parameter directory</li> <li><code>path_serde/</code>: Traits needed for all types available via Communication</li> <li><code>path_serde_derive/</code>: Derive macro for the <code>PathSerialize, PathDeserialize, PathIntrospect</code> trait</li> </ul> </li> <li><code>etc/</code>: All additional files necessary when deploying the code to a robot<ul> <li><code>parameters/</code>: Parameter files that are deployed to NAOs and are read during startup</li> </ul> </li> <li><code>tools/</code>: Miscellaneous projects and tools more or less related to the code<ul> <li><code>pepsi/</code>: Mainly a tool for deploying and interacting with the NAO</li> <li><code>twix/</code>: Current iteration of a debug tool</li> </ul> </li> </ul>"},{"location":"framework/error_handling/","title":"Error Handling","text":"<p>TODO: Elaborate</p> <ul> <li>Error Handling<ul> <li>3 ways to handle errors<ul> <li>Set a main output to none: Happens when the node is unable to generate this output (e.g. when inputs are not available or there was a temporary error inside of the node)<ul> <li>Recoverable, expected to be resolved in the next cycle</li> </ul> </li> <li>Return <code>Err(...)</code> from <code>cycle()</code><ul> <li>Unrecoverable, but framework is allowed to shutdown gracefully, expected that it will not improve in the next cycles/in the future</li> </ul> </li> <li>Panic with e.g. <code>panic!()</code> or by <code>unwrap()</code>ing<ul> <li>Unrecoverable, immediate shutdown, kernel will take down the whole process, there is no way to gracefully shutdown</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"framework/filtering/","title":"Filtering","text":"<p>TODO: Elaborate</p> <ul> <li>FutureQueue/Filtering<ul> <li>Overview: Time diagram/plot</li> <li>Motivation: Filters need to have monotonic updates<ul> <li>What needs a filter node to do in each cycle?<ul> <li>Roll-back temporary measurements from last cycle</li> <li>Apply persistent measurements</li> <li>Temporarily apply temporary measurements</li> </ul> </li> </ul> </li> <li>FutureQueue (each Perception Cycler has one to communicate to Control)<ul> <li>Producer<ul> <li>announce</li> <li>finalize</li> </ul> </li> <li>Consumer<ul> <li>consume</li> </ul> </li> </ul> </li> <li>PersistentDatabases consumes from multiple FutureQueues and reorganizes data<ul> <li>persistent vs. temporary</li> </ul> </li> <li>PersistentInputs (Interface for the filter nodes)<ul> <li>persistent vs. temporary</li> </ul> </li> </ul> </li> </ul>"},{"location":"framework/hardware_interface/","title":"Hardware Interface","text":"<p>TODO: Elaborate</p> <ul> <li>Hardware Interface<ul> <li>Trait<ul> <li><code>produce_sensor_data()</code></li> </ul> </li> <li>NAO<ul> <li>HardwareId retrieval (from HULA)</li> <li>LoLA/HAL/HULA<ul> <li>Explain abbreviations</li> <li>Overview: State/Connection/Network/Component Diagram, DataFlow Model</li> <li>Socket Location and that it is a Unix Socket</li> <li>Proxy<ul> <li>Message extraction and injection</li> <li>Message format</li> <li>LED animations</li> </ul> </li> <li>Aliveness<ul> <li>Network: Message format, UDP, multicast, JSON</li> <li>Service states</li> </ul> </li> <li><code>produce_sensor_data()</code></li> </ul> </li> <li>Cameras<ul> <li>Video4Linux</li> <li>Buffering, Zero-copy (-&gt; Cycler)</li> <li>Camera setup (registers)</li> </ul> </li> <li>Audio<ul> <li>ALSA</li> <li>ALSA configuration</li> <li>Later: Audio playback, Text-to-speech</li> </ul> </li> </ul> </li> <li>Webots<ul> <li>HardwareId retrieval (robot name)</li> <li>Webots bindings</li> <li><code>produce_sensor_data()</code></li> <li>Image, audio transfer to different threads</li> <li>Simulation World</li> <li>Directory structure, symlink</li> </ul> </li> </ul> </li> </ul>"},{"location":"framework/logging/","title":"Logging","text":"<p>TODO: Elaborate</p>"},{"location":"framework/macros/","title":"Macros","text":"<p>TODO: Elaborate</p> <ul> <li>Macros<ul> <li>What is a Rust macro? Gets a TokenStream as input, is able to transform it and outputs a new TokenStream</li> <li>Goal: Reduce code duplication, reduce manually-written code</li> <li>Node<ul> <li>Node declaration <code>#[node(...)]</code> Declare a node<ul> <li>Attached to <code>impl Node {}</code></li> <li>Add <code>struct CycleContext</code><ul> <li>Contains inputs, additional outputs, etc.</li> </ul> </li> <li>Add <code>impl CycleContext { fn new(...) -&gt; CycleContext {} }</code></li> <li>Add <code>struct MainOutputs</code><ul> <li>Contains main outputs</li> </ul> </li> <li>Add <code>impl MainOutputs { fn update(...) {} fn none() {} }</code></li> <li>Modify <code>impl Node {}</code>: Add <code>fn run_cycle() {}</code><ul> <li>Creates <code>CycleContext</code> and <code>MainOutputs</code></li> <li>Call <code>cycle()</code> method of the node</li> </ul> </li> </ul> </li> <li>Inputs<ul> <li>Input <code>#[input(path, data_type, cycler, name)]</code> Get data from this cycle within the current cycler</li> <li>Within control cycler:<ul> <li>Historic Input <code>#[historic_input(path, data_type, name)]</code> Get historic data from control cycler</li> <li>Perception Input <code>#[perception_input(path, data_type, cycler, name)]</code> Get perception data from perception cyclers</li> <li>Persistent State <code>#[persistent_state(path, data_type, name)]</code> Share state between nodes over multiple cycles</li> </ul> </li> <li>Parameter <code>#[parameter(data_type, name, path, on_changed)]</code> Get configuration parameters from the configuration file/via Communication</li> </ul> </li> <li>Outputs<ul> <li>Main Output <code>#[main_output(data_type, name)]</code> Output for dependent nodes, generated in every cycle</li> <li>Additional Output <code>#[additional_output(path, data_type, name)]</code> Optional output that can be enabled/requested from e.g. Communication</li> </ul> </li> </ul> </li> <li><code>require_some!</code> TODO: <code>required</code> flag?<ul> <li>Extracts data from cycle context and returns none for all main outputs if the input was none</li> <li><code>require_some!(...) =&gt; match ... { Some(...) =&gt; ..., None =&gt; return MainOutputs::none() }</code></li> </ul> </li> <li>3rd-party macros: <code>nalgebra::point</code> or <code>nalgebra::matrix</code><ul> <li>Link to 3rd-party documentation</li> </ul> </li> </ul> </li> </ul>"},{"location":"framework/nodes/","title":"Nodes","text":"<p>Nodes usually contain robotics code and are interchangeable components within cyclers. Each node is characterized by a <code>cycle()</code> function which is called in each cycle. The function gets node's inputs as parameters to the <code>cycle()</code> function and returns node's outputs from it. In addition, nodes consist of a state which is perserved between cycles.</p> <p></p> <p>Nodes are normal Rust structs where the struct's fields represent the state and a method called <code>cycle()</code> in the <code>impl</code> of the node represents the <code>cycle()</code> function. This concept allows to write nodes in a very Rusty way. A node may have multiple inputs of different kinds which can be annotated to the node. Here is an example node, but for more information see Macros:</p> <pre><code>pub struct SolePressureFilter { // (1)\nleft_sole_pressure: LowPassFilter&lt;f32&gt;,\nright_sole_pressure: LowPassFilter&lt;f32&gt;,\n}\n#[node(control)] // (2)\n#[parameter(path = low_pass_alpha, data_type = f32)] // (3)\n#[input(path = sensor_data, data_type = SensorData)] // (4)\n#[main_output(data_type = SolePressure)] // (5)\nimpl SolePressureFilter {} // (6)\nimpl SolePressureFilter {\nfn new(context: NewContext) -&gt; anyhow::Result&lt;Self&gt; { // (7)\nOk(Self {\nleft_sole_pressure: LowPassFilter::with_alpha(\n0.0,\n*context.low_pass_alpha, // (8)\n),\nright_sole_pressure: LowPassFilter::with_alpha(\n0.0,\n*context.low_pass_alpha,\n),\n})\n}\nfn cycle(&amp;mut self, context: CycleContext) -&gt; anyhow::Result&lt;MainOutputs&gt; { // (9)\nlet force_sensitive_resistors =\n&amp;require_some!(context.sensor_data).force_sensitive_resistors;\nlet left_sole_pressure = force_sensitive_resistors.left.sum();\nself.left_sole_pressure.update(left_sole_pressure);\nlet right_sole_pressure = force_sensitive_resistors.right.sum();\nself.right_sole_pressure.update(right_sole_pressure);\nOk(MainOutputs {\nsole_pressure: Some(SolePressure {\nleft: self.left_sole_pressure.state(),\nright: self.right_sole_pressure.state(),\n}),\n})\n}\n}\n</code></pre> <ol> <li>Node's state</li> <li>Node declaration with <code>node</code> macro</li> <li>Configuration parameter of type <code>f32</code></li> <li>Input of type <code>SensorData</code></li> <li>Output of type <code>SolePressure</code></li> <li>Empty <code>impl</code> to improve usability of language servers and code linters. If the node declaration would be attached to the <code>impl</code> below, when writing incomplete code, the macros would produce errors. This happens a lot if writing node implementation code.</li> <li>Will be called at construction of the node</li> <li>Use declared configuration parameter. Since it is a reference, we need to dereference it with <code>*</code>.</li> <li>Will be called every cycle</li> </ol> <p>This node consumes the type <code>SensorData</code> as input and produces the output <code>SolePressure</code>. It has two state variables <code>left_sole_pressure</code> and <code>right_sole_pressure</code>.</p> <p>This specification of node inputs and outputs leads to a dependency graph which allows to topologically sort nodes s.t. all dependencies are met before executing the node's <code>cycle()</code>. The <code>build.rs</code> file automatically sorts nodes based on this graph.</p>"},{"location":"framework/overview/","title":"Overview","text":"<p>TODO: Mention unit testing</p> <p>This section explains the framework of our NAO software. The chapters walk through various features in a top-down approach starting with a general overview. More advanced topics are covered later. Here is a short outline of the next chapters:</p> <ul> <li>Directory Structure: Explains the directory structure of the code repository</li> <li>Process EntryPoint: Starts the top-down approach from the <code>main()</code> function of the process</li> <li>Runtime: What does the runtime do to setup and inter-connect all subcomponents?</li> <li>Cyclers: How do cyclers run the robotics nodes?</li> <li>Nodes: What are nodes and how are they implemented?</li> <li>Databases &amp; Types: How can data be shared between cyclers and the framework?</li> <li>Parameters: How does the framework provide configuration parameters to nodes?</li> <li>Communication: What is communication and how is it able to communicate between framework and nodes?</li> <li>Hardware Interface: How is the hardware abstracted away for the different target platforms?</li> <li>Thread Communication: Which concepts and features exist to enable thread-safe communication between subcomponents?</li> <li>Filtering: How to interleave historic data in filters in an multi-threaded software?</li> <li>Macros: What macros exist that ease the development and how do they work?</li> <li>Error Handling: Which kinds of error handling concepts are supported and which to choose when?</li> </ul> <p>The framework provides the fundamentals needed to execute robotics specific code. It has a modular design to allow for convenient development and replacement of individual nodes. The framework consists of four fundamental components:</p> <ul> <li>Runtime: Encapsulates all subcomponents by starting and initializing them</li> <li>Hardware Interface: Abstracts hardware away and is the interaction point for cyclers with the outside world</li> <li>Cyclers: Cycle through nodes, process data from hardware and produce outputs (see e.g. control or vision_top)</li> <li>Communication: Exchanges data between framework and other resources e.g. file system and network</li> </ul> <p></p>"},{"location":"framework/parameters/","title":"Parameters","text":"<p>The robotic control software has some configuration parameters that affect calculations and the execution of the code. Modules can access deep fields in the hierarchy via a path.</p>"},{"location":"framework/parameters/#loading-and-modifications","title":"Loading and Modifications","text":"<p>The parameters are loaded from the file system. The parameter files are located in <code>etc/parameters/</code>. This directory also gets deployed to the NAO s.t. the <code>hulk</code> executable has access to it. Communication is able to mutate parameter values at runtime (but cannot store them back to files).</p>"},{"location":"framework/parameters/#overwriting","title":"Overwriting","text":"<p>The parameter directory allows to overwrite individual configuration fields in the object hierarchy. NAO robots have their cameras and mainboard in the head. The chestboard and motors are attached to the body. Each head and body of a NAO have unique IDs which are used to load specific configuration parameters. In addition, robots may need different parameters depending on the location. The location is selected in the parameter directory and points to a directory where overwriting parameter files are placed. To create a full parameter object from the whole parameter directory, the following procedure is used:</p> <ol> <li>Read and parse <code>etc/configuration/default.json</code></li> <li>If existing, read and parse...<ul> <li>For NAO: <code>etc/nao_location/default.json</code></li> <li>For Webots: <code>etc/webots_location/default.json</code></li> <li>For behavior simulator: <code>etc/simulated_behavior/default.json</code></li> </ul> </li> <li>If existing, read and parse <code>etc/body.{body_id}.json</code></li> <li>If existing, read and parse <code>etc/head.{body_id}.json</code></li> <li>If existing, read and parse...<ul> <li>For NAO: <code>etc/nao_location/body.{body_id}.json</code></li> <li>For Webots: <code>etc/webots_location/body.{body_id}.json</code></li> <li>For behavior simulator: <code>etc/simulated_behavior/body.{body_id}.json</code></li> </ul> </li> <li>If existing, read and parse...<ul> <li>For NAO: <code>etc/nao_location/head.{body_id}.json</code></li> <li>For Webots: <code>etc/webots_location/head.{body_id}.json</code></li> <li>For behavior simulator: <code>etc/simulated_behavior/head.{body_id}.json</code></li> </ul> </li> </ol> <p>The location directories are usually symlinks to actual directories with the location names. This allows to easily swap locations by retargeting the symlink.</p>"},{"location":"framework/path_serde/","title":"Path Serialization and Deserialization","text":"<p>The <code>path_serde</code> crate introduces essential interfaces for serializing and deserializing specific parts of types by providing paths to their internals. This functionality is mainly used by Communication to serialize data and provide it to connected debugging applications.</p>"},{"location":"framework/path_serde/#traits","title":"Traits","text":"<p>The crate provides three distinct traits: <code>PathSerialize</code>, <code>PathDeserialize</code>, and <code>PathIntrospect</code>.</p>"},{"location":"framework/path_serde/#pathserialize","title":"<code>PathSerialize</code>","text":"<p>The PathSerialize trait enables the serialization of specific parts of types by accepting a path to the desired internal data. This is particularly useful when only certain portions of a data structure need to be serialized.</p> <pre><code>trait PathSerialize {\nfn serialize_path&lt;S&gt;(&amp;self, path: &amp;str, serializer: S) -&gt; Result&lt;S::Ok, Error&lt;S::Error&gt;&gt;\nwhere\nS: Serializer;\n}\n</code></pre> <p>For instance a user is only interested in the position angle value of the ankle pitch joint, a serialization of the path <code>Control.main.sensor_data.positions.ankle_pitch</code> results in serializing only this specific float value.</p>"},{"location":"framework/path_serde/#pathdeserialize","title":"<code>PathDeserialize</code>","text":"<p>Conversely, the <code>PathDeserialize</code> trait facilitates the deserialization of data into types given a specified path.</p> <pre><code>trait PathDeserialize {\nfn deserialize_path&lt;'de, D&gt;(\n&amp;mut self,\npath: &amp;str,\ndeserializer: D,\n) -&gt; Result&lt;(), Error&lt;D::Error&gt;&gt;\nwhere\nD: Deserializer&lt;'de&gt;;\n}\n</code></pre> <p>This functionality is used when changing only parts of parameters.</p>"},{"location":"framework/path_serde/#pathintrospect","title":"<code>PathIntrospect</code>","text":"<p>The <code>PathIntrospect</code> trait enables type introspection, allowing the user to generate a set of available paths to fields of a type. This functionality is valuable for dynamically exploring the structure of data types and determining the paths that can be utilized for serialization and deserialization. For instance, tooling may use these paths to autocomplete available paths when subscribing data from the robot.</p>"},{"location":"framework/path_serde/#macro","title":"Macro","text":"<p><code>path_serde</code> also provides derive macros, automatically generating the implementation of the three traits. The source of an annotated type is analyzed and implementation is generated for each field, delegating the call to sub-types.</p>"},{"location":"framework/path_serde/#attributes","title":"Attributes","text":"<p>Types and fields can be additionally annotated with attributes to modify code generation. Each attribute is prefixed with <code>#[path_serde(&lt;...&gt;)</code> to identify attributes to the <code>path_serde</code> macros. We define the following attributes:</p>"},{"location":"framework/path_serde/#container-bound","title":"Container: <code>bound</code>","text":"<p>This attribute is attached to a container type and defines generic where bounds to the implementation.</p> <pre><code>#[derive(Serialize, PathSerialize)]\n#[path_serde(bound = T: PathSerialize + Serialize)]\nstruct MyStruct&lt;T&gt; {\nfoo: T,\n}\n</code></pre>"},{"location":"framework/path_serde/#container-add_leaf","title":"Container: <code>add_leaf</code>","text":"<p>The <code>add_leaf</code> attribute adds an additional leaf to the children of a type by specifying a leaf name and a type. This type is required to implement a <code>TryFrom&lt;Self&gt;</code> to generate the data for this field when requested. Additionally, this type must be serializable or deserializable.</p> <pre><code>#[derive(Serialize, PathSerialize)]\n#[path_serde(add_leaf(bar: MyIntoType)]\nstruct MyStruct {\nfoo: i32,\n}\n</code></pre>"},{"location":"framework/path_serde/#field-leaf","title":"Field: <code>leaf</code>","text":"<p>This attributes tags a field to be a leaf of the tree. That means, it is not expected to have further children, and path delegation ends at this field.</p> <pre><code>#[derive(Serialize, PathSerialize)]\npub struct MultivariateNormalDistribution {\npub mean: f32,\n#[path_serde(leaf)]\npub covariance: FancyType,\n}\n</code></pre>"},{"location":"framework/path_serde/#field-skip","title":"Field: <code>skip</code>","text":"<p>This attributes tags a field to be skipped for the implementation. It is neither considered for (de-)serialization, nor included in the available paths.</p> <pre><code>#[derive(Serialize, PathSerialize)]\npub struct MultivariateNormalDistribution {\npub mean: f32,\n#[path_serde(skip)]\npub covariance: FancyType,\n}\n</code></pre>"},{"location":"framework/path_serde/#example-usage","title":"Example Usage","text":"<pre><code>#[derive(PathSerialize, PathDeserialize, PathIntrospect)]\nstruct ExampleStruct {\nfoo: u32,\nbar: String,\n}\nfn main() {\nlet example = ExampleStruct {\nfoo: 42,\nbar: String::from(\"example\"),\n};\n// Serialize data using path\nlet serialized_data = example.serialize_path(\"foo\", /* serializer */);\n// Deserialize data from a specified path\nlet deserialized_data = example.deserialize_path(\"bar\", /* deserializer */);\n// Generate a set of all available paths within ExampleStruct\nlet available_paths = ExampleStruct::get_fields();\n}\n</code></pre>"},{"location":"framework/process_entrypoint/","title":"Process Entrypoint","text":"<p>The HULKs robotic control software can be compiled for multiple build targets e.g. NAO and Webots. Each build target results in a executable which is either executed directly on the NAO or on the development machine. All executables define a <code>main()</code> function as entrypoint for the robotic control software, see <code>crates/hulks_nao</code> or <code>crates/hulks_webots</code> in the code. The following sections explain the first setup steps done in the <code>main()</code> function for the major build targets NAO and Webots.</p>"},{"location":"framework/process_entrypoint/#hardware-parameters","title":"Hardware Parameters","text":"<p>Later in the <code>main()</code>, the hardware interfaces are created. Beside the robotics domain, the hardware interface also needs some configuration parameters to initialize the hardware. Thes parameters are read from a JSON file that can be passed as first command line argument to the executable. If omitted, the file at <code>etc/parameters/hardware.json</code> is loaded.</p>"},{"location":"framework/process_entrypoint/#shutdown-and-cancellationtoken","title":"Shutdown and CancellationToken","text":"<p>The <code>main()</code> functions for the NAO and Webots targets register shutdown handlers via the Rust crate ctrlc. These shutdown handlers react on the Linux signals <code>SIGINT</code> and <code>SIGTERM</code> to call <code>CancellationToken::cancelled()</code> which cancels the <code>CancellationToken</code> on signal receival. The <code>CancellationToken</code> is a synchronization primitive which is shared with the whole framework and robotics code to allow to shutdown all subcomponents from any location. Several places listen for the <code>cancelled()</code> event and terminate on cancellation. Beside cancelling the <code>CancellationToken</code> on Linux signals, error conditions within the robotic control software can trigger a cancellation as well. This concept allows to shutdown gracefully in any case of error or termination request.</p>"},{"location":"framework/process_entrypoint/#hardware-interface-runtime","title":"Hardware Interface &amp; Runtime","text":"<p>On NAO and in Webots the robotic control software needs access to the hardware or simulator interface. The hardware interface provides an abstract way to interact with the underlying backend. The <code>main()</code> function first initializes the hardware interface and then starts the runtime (<code>run()</code>) with it. See Hardware Interface for more information about what the hardware interface initializes.</p>"},{"location":"framework/runtime/","title":"Runtime","text":"<p>The runtime is the component in the robotic control software that encapsulates all subcomponents e.g. the hardware interface, cyclers, and communication. Here is a more detailed overview extending the drawing from Overview:</p> <p></p> <p>This section and following ones will cover this drawing in more detail. Many dataflow connections are still left out to improve readability.</p> <p>The runtime is constructed with an already existing and initialized hardware interface. The runtime contains all subcomponents and therefore is in charge to construct them. Subcomponents require to be interconnected with each other. The runtime therefore creates all necessary communication channels and buffers that are shared between the subcomponents. More details on the connections between cyclers and communication are given in Communication.</p> <p>The communication subcomponent and each cycler are executed in separate threads which are started. The next section Cyclers talks more about the cyclers.</p>"},{"location":"framework/thread_communication/","title":"Thread Communication","text":"<p>TODO: Elaborate</p> <ul> <li>Buffering/Thread Communication/Channels<ul> <li>Tokio CancellationToken</li> <li>n-tuple Buffer<ul> <li>Related to Triple Buffer</li> <li>Guarantees, Assumptions</li> </ul> </li> <li>Tokio channels</li> <li>Channel flow diagram (mostly Cycler&lt;-&gt;Cycler and Cycler&lt;-&gt;Communication)</li> </ul> </li> </ul>"},{"location":"operating_system/home_directory/","title":"Home Directory","text":"<p>The home directory (<code>/home/nao/</code>) is overlayed with a mount to the <code>/data</code> partition (see Partitioning).</p> <p>When flashing the robot and uploading the hulk binary, the home directory structure looks as follows:</p> <pre><code>.\n|-- hulk\n|   |-- bin\n|   |   `-- hulk\n|   |-- etc\n|   |   |-- parameters\n|   |   |   `-- *.json\n|   |   |-- motions\n|   |   |   `-- *.motion2\n|   |   |-- neural_networks\n|   |   |   `-- *.hdf5\n|   |   |-- poses\n|   |   |   `-- *.pose\n|   |   `-- sounds\n|   |       `-- *.ogg\n|   `-- logs\n|       |-- hulk-1667906932.err\n|       |-- hulk-1667906932.out\n|       |-- hulk.err -&gt; /home/nao/hulk/logs/hulk-1667906932.err\n|       `-- hulk.out -&gt; /home/nao/hulk/logs/hulk-1667906932.out\n`-- robocup.conf\n</code></pre> <p>The <code>./robocup.conf</code> file is required to start the LoLA service in robocupper mode. All files related to the hulk service and binaries are stored in the subdirectory <code>hulk</code> and mirrors the files of the directory structure of the development repository (Directory Structure).</p>"},{"location":"operating_system/hula/","title":"HULA","text":"<p>TODO</p>"},{"location":"operating_system/linux/","title":"Linux","text":"<p>The Nao uses a Linux 5.4 real time kernel for intel processors (linux-intel/preempt-rt).</p> <p>Most of the kernel configuration is done by the <code>meta-intel</code> layer for yocto. Special modifications for the Nao robot are contained in the <code>meta-nao</code> layer and mainly consist of patches and kernel modules by aldebaran for chestboard communication.</p>"},{"location":"operating_system/overview/","title":"Overview","text":"<p>TODOs:</p> <ul> <li>Chapter introduction</li> <li>HULA</li> </ul>"},{"location":"operating_system/overview/#outline","title":"Outline","text":"<ul> <li>Partitioning</li> <li>Home Directory</li> <li>Linux</li> <li>WiFi</li> <li>HULA</li> </ul>"},{"location":"operating_system/partitioning/","title":"Partitioning","text":"<p>The Nao uses a single flash storage device for main storage purposes. After a successfully flashing the robot with the HULKs OS, this storage device is recogniced as <code>/dev/mmcblk1</code>. The device counts 4 separate partitions.</p> <pre><code>NAME          SIZE MOUNTPOINTS\nmmcblk1      29.1G\n|-mmcblk1p1   128M /media/internal\n|-mmcblk1p2    64M\n|-mmcblk1p3   3.8G /\n`-mmcblk1p4  25.1G /data\n</code></pre>"},{"location":"operating_system/partitioning/#softbank-partition-mmcblk1p1","title":"Softbank partition <code>mmcblk1p1</code>","text":"<p>The first partition is called 'internal' and is used by softbank binaries and during the flashing. The partition is mounted by default at <code>/media/internal</code> and is required to be mounted when using LoLA or HAL. During standard use, this partition is not accessed by HULKs binaries.</p> <p>Softbank uses this partition to store general information about the robot, such as IDs. The aldebaran script <code>/opt/aldebaran/head_id</code> for example uses the file <code>/media/internal/DeviceHeadInternalGeode.xml</code> to query the id of the head.</p>"},{"location":"operating_system/partitioning/#efi-partition-mmcblk1p2","title":"EFI partition <code>mmcblk1p2</code>","text":"<p>The second partition is the EFI boot partition and not mounted by default. To inspect the EFI files mount this partition:</p> <pre><code>sudo su\nmount /dev/mmcblk1p2 /mnt/\n# inspect files at /mnt/\n</code></pre>"},{"location":"operating_system/partitioning/#root-partition-mmcblk1p3","title":"Root partition <code>mmcblk1p3</code>","text":"<p>The third partition is the root partition. This partition is created and managed by the yocto configuration and usually not inteded to be modified at runtime.</p>"},{"location":"operating_system/partitioning/#data-partition-mmcblk1p4","title":"Data partition <code>mmcblk1p4</code>","text":"<p>The fourth and last partition is for runtime data storage. It is mounted to <code>/data</code> by default.</p> <p>When first booting up the system, the two system units <code>data-format</code> and <code>data-skeleton</code> are responsible of setting up the partition and directory structure. The <code>data-format</code> unit is run once before mounting the partition to create a new filesystem and disables itself afterwards. The <code>data-skeleton</code> unit is run every startup and provides a directory structure for following overlay mounts.</p>"},{"location":"operating_system/partitioning/#home-directory-homenao","title":"Home directory <code>/home/nao</code>","text":"<p>The home directory is used for custom user code and also for storing and executing the <code>hulk</code> binary. It is an overlay mount specified in the <code>/etc/fstab</code>:</p> <pre><code>[...]\noverlay /home/nao overlay lowerdir=/home/nao,upperdir=/data/home/nao,workdir=/data/.work-home-nao 0 0\n[...]\n</code></pre>"},{"location":"operating_system/wifi/","title":"WiFi","text":"<p>The WiFi is supplied by a Qualcomm Atheros AR9462 and configured via the iNet Wireless Daemon (iwd). For more information on iwd visit their documentation.</p>"},{"location":"operating_system/wifi/#iwd-configuration","title":"<code>iwd</code> Configuration","text":"<p>The iwd service can be manually configured using the command line interface tool <code>iwctl</code>. For persistent configuration iwd stores <code>*.psk</code> files for every known SSID at <code>/var/lib/iwd/</code>. The yocto distribution installs those <code>*.psk</code> files for the network SSIDs SPL_A to SPL_F.</p> <pre><code>[Security]\nPassphrase=Nao?!Nao?!\n\n[Settings]\nAutoConnect=false\n</code></pre> <p>Automatic connection is disabled to prevent the Nao to connect to any SPL network in range. If iwd was tasked to connect to a network once, it tries to reconnect to that same SSID until the daemon is instructed to disconnect.</p> <p>The iwd is also able configure IP settings and run DHCP. This is called Network Configuration and disabled via the <code>/etc/iwd/main.conf</code>. IP configuration is and done by systemd-networkd.</p> <pre><code>[General]\nEnableNetworkConfiguration=false\n</code></pre>"},{"location":"operating_system/wifi/#ip-configuration","title":"IP Configuration","text":"<p>The Nao's IP address is derived from the robots id number in the <code>../setup/nao_image_and_sdk.md</code>. This follows the pattern <code>10.{Interface}.{TeamNumber}.{NaoNumber}</code>. For the robot 22 of team HULKs this is <code>10.0.24.22</code> on the wireless interface and <code>10.1.24.22</code> on the wired interface.</p> <p>Responsible for the configuration is the systemd unit <code>network-config</code> running the <code>/usr/sbin/configure_network</code> script once per boot. This script is calculating the IP configuration based on the entries in the <code>/etc/id_map.json</code> and generates systemd network configuration files at <code>/etc/systemd/network/80-wlan.network</code> and <code>/etc/systemd/network/80-wired.network</code>.</p>"},{"location":"robotics/overview/","title":"Overview","text":"<p>Currently there are 5 different threads, termed cyclers in hulks terminology</p> <ul> <li><code>Control</code></li> <li><code>VisionTop</code></li> <li><code>VisionBottom</code></li> <li><code>Audio</code></li> <li><code>SPLNetwork</code></li> </ul>"},{"location":"robotics/overview/#control","title":"<code>Control</code>","text":""},{"location":"robotics/overview/#visiontopbottom","title":"<code>VisionTop/Bottom</code>","text":""},{"location":"robotics/overview/#audio","title":"<code>Audio</code>","text":""},{"location":"robotics/overview/#splnetwork","title":"<code>SPLNetwork</code>","text":"<p>TODO: Elaborate</p>"},{"location":"robotics/overview/#perception","title":"Perception","text":"<ul> <li>Filters</li> <li>SPL Network (GameController communication, Team communication)</li> <li>Vision</li> <li>Whistle Detection/Audio</li> </ul>"},{"location":"robotics/overview/#behavior","title":"Behavior","text":"<ul> <li>World state -&gt; Actions -&gt; MotionCommand</li> </ul>"},{"location":"robotics/overview/#motion","title":"Motion","text":"<ul> <li>Step planning</li> <li>Walking</li> <li>Kicking</li> <li>...</li> </ul>"},{"location":"robotics/miscellaneous/create_urdf/","title":"Create URDF and PROTO for NAOv6","text":"<p>For Webots we need a PROTO file which should contain 3D models and the scene graph of the NAOv6. The only source is a URDF from http://doc.aldebaran.com/2-8/family/nao_technical/kinematics_naov6.html#naov6-urdf-files. Meshes in OGRE mesh format can be found in e.g. the \"C++ SDK\" from https://developer.softbankrobotics.com/nao6/downloads/nao6-downloads-linux (in <code>share/alrobotmodel/meshes</code>). The URDF and meshes need to be converted to Webots PROTO.</p> <p>Download and build target <code>OgreXMLConverter</code> in https://github.com/OGRECave/ogre (e.g. <code>cmake --build build --target OgreXMLConverter</code>). <code>OgreXMLConverter</code> is able to convert OGRE mesh files into XML files containing the raw vertices and face vector indices. The resulting XML files can be converted into binary STL files with the script <code>xml_to_stl.py</code>.</p> <p>The script above generates multiple STL files for each submesh contained in the XML file. This allows to set different materials in the URDF. The material's name is included in the STL filename. Since the URDF only references the old mesh files it needs to be adapted to contain multiple <code>&lt;visual&gt;</code> sections with same translation and rotation but with different STL mesh files and materials (<code>package://</code> prefixes can be dropped).</p> <p>Cameras can be added with e.g.:</p> <pre><code>&lt;gazebo reference=\"CameraTop\"&gt;\n&lt;sensor type=\"camera\" name=\"CameraTop\"&gt;\n&lt;camera name=\"CameraTop\"&gt;\n&lt;horizontal_fov&gt;0.982122222&lt;/horizontal_fov&gt;\n&lt;image&gt;\n&lt;width&gt;640&lt;/width&gt;\n&lt;height&gt;480&lt;/height&gt;\n&lt;format&gt;R8G8B8A8&lt;/format&gt;\n&lt;/image&gt;\n&lt;/camera&gt;\n&lt;/sensor&gt;\n&lt;/gazebo&gt;\n</code></pre> <p>And an IMU with e.g.:</p> <pre><code>&lt;gazebo reference=\"Accelerometer\"&gt;\n&lt;plugin filename=\"libgazebo_ros_imu.so\"&gt;\n&lt;topicName&gt;IMU&lt;/topicName&gt;\n&lt;/plugin&gt;\n&lt;/gazebo&gt;\n</code></pre> <p>The URDF is as complete as it can get. The URDF with STLs can be converted with https://github.com/cyberbotics/urdf2webots to a PROTO file. <code>urdf2webots</code> only converts a subset of sensors (https://github.com/cyberbotics/urdf2webots/blob/6630d9778af064983f97ef1b2ea87f91c1efb48b/urdf2webots/parserURDF.py#L986-L1080) and has only limited conversion capabilities for meshes etc. At this point the PROTO file needs to be finalized manually.</p> <p>Cameras are wrongly oriented and need to be rotated: Both camera's rotation needs to be <code>rotation 0.577350 -0.577350 -0.577350 2.093333333</code>.</p> <p>If not setting all initial joint angles to zero, the robot seems to have random initial angles in Webots. Therefore specify <code>--init-pos=\"[0.0, 0.0, 0.0, ..., 0.0, 0.0]\"</code> to <code>urdf2webots</code> (the amount of <code>0.0</code> corresponds to the number of joints, e.g. 130).</p>"},{"location":"robotics/motion/motion_files/","title":"Motion Files","text":""},{"location":"robotics/perception/vision/","title":"Vision","text":"<p>TODO: Mention all nodes or just the important ones? Nodes of questionable importance:</p> <ul> <li>Field color detection</li> <li>Camera matrix provider</li> </ul> <p>TODO: Add images</p> <p>The vision cycler runs twice in two separate threads to process the images from the top and bottom camera in parallel.</p> <p>Image resolution is determined by the hardware interface, but is currently set to 640x480 pixels for performance reasons. Most of the vision pipeline happens on a segmented version of the image for the same reason.</p> <p>Each cycler instance waits for the hardware interface to deliver it's respective camera image and then begins executing the nodes listed below.</p>"},{"location":"robotics/perception/vision/#camera-matrix-provider","title":"Camera Matrix Provider","text":""},{"location":"robotics/perception/vision/#field-color-detection","title":"Field Color Detection","text":""},{"location":"robotics/perception/vision/#image-segmenter","title":"Image Segmenter","text":"<p>The first major node in the vision pipeline is the image segmenter. It iterates through the image and merges vertically adjacent pixels that are similar. This reduces the amount of elements subsequent nodes have to process. Instead of 480 pixels, each vertical scan line is reduced to just a dozen or so segments, depending on the image. A stride can be set to only generate scanlines for every n-th pixel column. Furthermore, segments which are above the horizon or overlap the robots limbs are discarded, resulting in a sparse image.</p> <p>Each segment contains it's location, color, edge types, and a pre-calculated classification of field color intensity.</p>"},{"location":"robotics/perception/vision/#field-border-detection","title":"Field Border Detection","text":"<p>Estimates the location of the upper field border in the image by finding the first pixels from the top that are roughly field-colored and fitting a line through them.</p>"},{"location":"robotics/perception/vision/#segment-filter","title":"Segment Filter","text":"<p>The image segments are further reduced by removing all segments that are considered field color to only preserve relevant features. Segments above the field border are also removed.</p>"},{"location":"robotics/perception/vision/#line-detection","title":"Line Detection","text":"<p>Using the filtered segments, field lines are detected by looking for white segments of appropriate length. For each segment the brightness gradient at each end is calculated using the Sobel operator. The segment is discarded if the gradients are not sufficiently steep upwards and downwards, i.e. the segment borders do not lie on opposite flanks of a field line.</p> <p>The center of each remaining segment is then used in a RANSAC line fitting algorithm. Found lines are projected onto the ground and then checked against those found previously to see if they are either parallel or orthogonal to each other.</p> <p>TODO: Why check parallelism and orthogonality? What do we do with this information?</p>"},{"location":"robotics/perception/vision/#perspective-grid-candidate-provider","title":"Perspective Grid Candidate Provider","text":"<p>This node generates candidates for the Ball Detection. Starting from the bottom of the image, rows of circles are generated where the circle size matches the projected ball in the row's center. Candidates are only generated when the center of at least one filtered segment is inside the candidate circle's bounding box.</p>"},{"location":"robotics/perception/vision/#ball-detection","title":"Ball Detection","text":"<p>For each perspective grid candidate a series of artifical neural networks is used to determine whether it contains a ball as well as the balls location and radius. First, a slightly larger sample centered around the candidate is extracted from the raw image. This sample is scaled up or down to 32x32 pixels, regardless of the size in the raw image.</p> <p>The first neural network to run on the image is called the \"preclassifier\", which is a small but cheap model to quickly filter out candidates that are clearly not a ball.</p> <p>If the preclassifier claims to have found a ball, a larger and more accurate network, the \"classifier\", is executed to decide whether the candidate contains a ball or not.</p> <p>Once the classifier finds a ball, a third neural network, the \"positioner\", is used to determine the location and size of the ball within the sample. These values are then transformed back into the coordinate frame of the image and then projected onto the field to determine the final location of the detected ball.</p> <p>TODO: Clustering</p> <p></p> <p>TODO: Implement this view in twix and update screenshot</p> <p>Debug view showing:</p> <ul> <li>blue circle: candidates from the perspective grid</li> <li>green circle: positioner network output</li> <li>white circle: clustered ball location</li> <li>red circle: current ball model, see filters</li> <li>black text: preclassifier confidence</li> </ul>"},{"location":"robotics/perception/vision/#robot-detection","title":"Robot Detection","text":"<p>Warning: This node is still work in progress.</p> <p>For detecting robots, a clustering algorithm runs through each vertical scanline of the filtered image segments, ignoring segments that have been previously used by the ball detection or line detection. The last (bottom most) cluster in each scanline is then projected to the ground and clustered first using the score-weighted distance and then again using cones.</p> <p>TODO: What does this mean? Why do we do this?</p>"},{"location":"setup/configure_team/","title":"Configuring Team Specific Data","text":"<p>Todo</p> <p>This page has to be improved.</p>"},{"location":"setup/configure_team/#hulks-members","title":"HULKs Members","text":"<p>There is nothing to do, all the configuration should be ready to go if you cloned the <code>hulks/hulk</code> repository.</p>"},{"location":"setup/configure_team/#non-hulks-members","title":"Non HULKs Members","text":""},{"location":"setup/configure_team/#set-up-team-number","title":"Set up Team Number","text":"<p>In the HULKs code release, the SPL team number is hardcoded in a few places. Change this to your own team number before continuing.</p> <ul> <li><code>crates/spl_network/src/lib.rs</code> contains a constant called <code>HULKS_TEAM_NUMBER</code>. You may also wish to rename this constant.</li> <li><code>tools/pepsi</code> contains a bunch of <code>24</code>s, however most of them are in comments or CLI command help text.<ul> <li><code>tools/pepsi/src/parsers.rs</code> has a default and a check value that use 24 literals.</li> </ul> </li> <li><code>tools/twix/src/completion_edit.rs</code> generates IP address suggestions with a hardcoded team number.</li> <li><code>etc/parameters/hardware.json</code> has an attribute called spl for team communication hardcoded to 10024 (10000 + team number).</li> </ul>"},{"location":"setup/configure_team/#set-up-hardware-ids","title":"Set up Hardware IDs","text":"<p>The tooling around our framework expects each NAO robot to have a number associated with it's hardware IDs. This number also determines the last octet of a robot's IP addresses. For example robot number <code>21</code> will always have the IPv4 addresses <code>10.0.X.21</code> (wireless) and <code>10.1.X.21</code> (ethernet) where X is the team number.</p> <p>For each robot you must determine it's head and body IDs and enter them in <code>etc/parameters/hardware_ids.json</code>. This file is used by pepsi and other tools to find the hardware ids belonging to a robot number.</p>"},{"location":"setup/development_environment/","title":"Setup Development Environment","text":"<p>This section will guide you through the setup of your development environment to build software for the NAO robot and test your algorithms using our various tools.</p>"},{"location":"setup/development_environment/#installing-rust","title":"Installing Rust","text":"<p>We require a latest stable release of the Rust toolchain to build our tools. Visit https://rustup.rs/ for up to date instructions on how to install <code>rustup</code> for your machine.</p>"},{"location":"setup/development_environment/#installing-dependencies","title":"Installing Dependencies","text":"<p>Our software requires a few dependencies to be installed before you can compile, upload, and run our code. Most of these dependencies are needed for the compilation of local tools. All dependencies needed for a cross-compilation for the NAO are included in the NAO SDK. Use your distribution's package manager to install the following dependencies:</p> <ul> <li>Git, Git LFS</li> <li>clang</li> <li>python3</li> <li>which</li> <li>zstd</li> <li>xz</li> <li>file</li> <li>rsync</li> </ul> Arch LinuxFedoraUbuntu <pre><code>sudo pacman -S git git-lfs clang python3 which zstd xz file rsync\n</code></pre> <pre><code>sudo dnf install git git-lfs clang python3 which zstd xz file rsync\n</code></pre> <pre><code>sudo apt install git git-lfs clang python3 zstd xz-utils file rsync\n</code></pre>"},{"location":"setup/development_environment/#cloning-the-repository","title":"Cloning the Repository","text":"<p>We use Git to manage all our software.</p> Git Setup: If you haven't used Git before <p>Git is a free and open source distributed version control system.</p> <p>First, install Git (see above).</p> <p>The second thing you should is to set your user name and email address. This is important because every Git commit uses this information, and it\u2019s baked into the commits you start creating:</p> <pre><code>git config --global user.name \"&lt;your-name&gt;\"\ngit config --global user.email \"&lt;your-email&gt;\"\n</code></pre> <p>And third, setup authentication with GitHub You can access and write data in repositories on GitHub.com using SSH (Secure Shell Protocol). When you connect via SSH, you authenticate using a private key file on your local machine. You can follow this guide to generate and add a key to GitHub. If you already have a key, you can skip the part about generating a new one, and simply add your existing key to GitHub.</p> <pre><code>git clone https://github.com/hulks/hulk.git\n</code></pre>"},{"location":"setup/development_environment/#build-pepsi","title":"Build Pepsi","text":"<p>Pepsi is our main tool to interact with the repository, configure NAOs, and upload the software to the robot. For a more in depth overview and introduction to Pepsi, consult [../tooling/pepsi.md].</p> <p>For now, it is sufficient to know that Pepsi takes care of building the source code and also uploading it to the NAO. This includes downloading and installing the SDK.</p> <p>To build and run Pepsi from source, use</p> <pre><code>./pepsi\n</code></pre> <p>This downloads and builds all dependencies for the workspace and displays the help page of Pepsi.</p> <p>Tip</p> <p>You can also install Pepsi into your local system to conviniently use it without rebuilding:</p> <pre><code>cargo install --path tools/pepsi\n</code></pre> <p>Pepsi is subsequently installed at <code>~/.cargo/bin/pepsi</code>.</p>"},{"location":"setup/nao_image_and_sdk/","title":"NAO Image &amp; SDK","text":"<p>The HULKs use the Yocto Project for creating a custom linux distribution, we call HULKs-OS. The toolchain compiles all necessary dependencies, tools, and kernel to produce flashable OPN images for the NAO. Additionally, Yocto provides means to construct a corresponding software development kit (SDK) containing a complete cross-compilation toolchain.</p> <p>Team HULKs automatically releases the latest HULKs-OS publicly on GitHub here. If you're looking to use these images or SDKs for flashing and deploying software onto your robot, you can opt for the pre-built versions and do not need to build your own image and SDK.</p> <p>Upon booting, the image automatically configures both wired and wireless network devices for the NAO. Each robot is identified by its unique Head-ID, which is used to assign a distinct IP address. The mapping between Head-IDs and IP addresses is configured in the image (here). All HULKs robots come pre-configured in the released images, via the <code>configure_network</code> service (here). But if you're flashing a new or non-HULKs robot, you'll need to add its head ID to the map and generate a new image.</p> <p>For robots not listed, the image falls back to configuring its wired network device via DHCP. Thus, you're free to flash the HULKs-OS image onto a robot and find its IP address by inspecting your DHCP leases or asking your IT administrator.</p>"},{"location":"setup/nao_image_and_sdk/#image-sdk-creation","title":"Image &amp; SDK Creation","text":"<p>The Yocto Project leverages BitBake as task execution engine and offers an abstraction layer to modify and extend existing build configurations. Combined with OpenEmbedded, the entire worktree is structured in several layers configuring the distribution and providing support for dependencies or services. Basic NAO support to construct a distribution for a minimal NAO robot operating system for use in SPL is configured with the root <code>meta</code>-layer in the <code>meta-nao</code> repository. The HULKs overlay this configuration with an additional <code>meta-hulks</code> layer to target the special HULKs usecase.</p>"},{"location":"setup/nao_image_and_sdk/#setup-of-the-working-directory","title":"Setup of the Working Directory","text":"<p>Start by cloning the code and setting up a Yocto working directory. This working directory will contain the yocto configuration layers, including HULKs/meta-nao and meta-hulks.</p> <pre><code>mkdir yocto/\ncd yocto/\n</code></pre> <p>Danger</p> <p>For creating the image and SDK, make sure there is at least 100 GB empty disk space available.</p> <p>Continue by cloning the <code>meta-nao</code> repository:</p> <pre><code>git clone git@github.com:HULKs/meta-nao\n</code></pre> <p>For project setup we use siemens/kas, a setup tool for bitbake based projects. To run kas, either install it locally (see here), or use the containerized version via the kas-container script. We prefer the containarized solution, as the container comes with all batteries included. The <code>kas-container</code> script makes it easy to spin a container (via podman or docker).</p> <pre><code>wget https://raw.githubusercontent.com/siemens/kas/master/kas-container\nchmod u+x kas-container\n</code></pre> <p>Subsequently, you can clone all necessary layers, we specify in our <code>kas-project.yml</code>. This file defines the project structure <code>kas</code> has to setup for the Yocto build phase.</p> <pre><code>./kas-container checkout meta-hulks/kas-project.yml\n</code></pre> <p>The last step is to populate the working directory with the proprietary and closed source software by aldebaran. This mainly is LoLA and HAL for communication with the chestboard. We do not provide these binaries, but rather extract them from the <code>.opn</code> files shipped with the RoboCupper image. To get the Robocupper image, HULKs members can ask our dev-leads, and non HULKs members should contact the RoboCup SPL Technical Committee.</p> <p>To extract the necessary binaries we provide a helper script called <code>extract_binaries.sh</code>. This script mounts the file system contained in the OPN image, fetches all binaries from inside the RoboCupper image, and collects them in an archive for the upcoming build phase. Mounting the OPN file system may require root privileges.</p> <pre><code>cd meta-nao/recipes-support/aldebaran/\nmkdir -p aldebaran-binaries\n./extract_binaries.sh -o aldebaran-binaries/aldebaran_binaries.tar.gz nao-2.8.5.11_ROBOCUP_ONLY_with_root.opn\n</code></pre> <p>Now your working directory is ready to build your own NAO image and SDK. At this point, you may adjust the distribution to your liking. This includes adding hardware IDs, configuring network, installing additional dependencies, and much more.</p> <p>Todo</p> <p>Explain what to do when configuring a new robot.</p>"},{"location":"setup/nao_image_and_sdk/#starting-a-build-shell","title":"Starting a Build Shell","text":"<p><code>kas</code> is able to start a shell inside of the build environment. The <code>kas-project.yml</code> of meta-nao needs to be referenced:</p> <pre><code># working directory is `yocto`\n./kas-container shell meta-nao/kas-project.yml\n</code></pre> <p>All BitBake and Devtool commands must be executed from inside this shell.</p>"},{"location":"setup/nao_image_and_sdk/#building-the-image","title":"Building the Image","text":"<p>Inside of the build shell, you can build a NAO OPN image and SDK via BitBake. The initial build may take multiple hours depending on your computing performance and download speed. Remember, you are building an entire linux distribution. BitBake provides advanced caching of the build artifacts which means that future builds are done in minutes or even seconds depending on the changes. The cache relies in the <code>build/sstate-cache</code> which can be copied from another build directory or even shared between machines, see Yocto Documentation about Shared State Cache for further explanation. To build the image, run the following command from inside the build shell:</p> <pre><code>bitbake nao-image\n</code></pre> <p>This generates and executes all necessary tasks and targets to construct a proper <code>.opn</code> file. After BitBake finishes the <code>nao-image</code> task, the image file can be found at <code>build/tmp/deploy/images/nao-v6/nao-image-HULKs-OS-[...].ext3.gz.opn</code>. The image can directly be flashed to a NAO as described in the NAO setup section.</p>"},{"location":"setup/nao_image_and_sdk/#building-the-sdk","title":"Building the SDK","text":"<p>To be able to compile software targeting the NAO platform, the code needs to be cross compiled for the NAO target. When you only change configuration for the NAO image, you may still maintain compatibility with the publicly released SDK at meta-nao and opt for this SDK instead of building your own.</p> <p>Within the build shell, the following command will build a full SDK:</p> <pre><code>bitbake -c populate_sdk nao-image\n</code></pre> <p>Again, this build phase may take several hours. After a successful build, the SDK is located at <code>build/tmp/deploy/sdk/HULKs-OS-toolchain-[...].sh</code>. To install the SDK run the script and follow the instructions. Afterwards, you are able to source the build environment and use the respective cross compilers.</p>"},{"location":"setup/nao_image_and_sdk/#advanced","title":"Advanced:","text":""},{"location":"setup/nao_image_and_sdk/#upgrade-other-yocto-layers","title":"Upgrade other Yocto Layers","text":"<p>The Yocto Project and the Poky reference distribution provide a Linux kernel, userland programs, libraries, and other tooling. All these things are updated in the regular Yocto releases. To ensure deterministic builds the HULKs freeze versions of all used layers in the <code>kas-project.yml</code> files of meta-nao.</p>"},{"location":"setup/nao_image_and_sdk/#upgrade-imagesdk-versions-and-semantic-versioning","title":"Upgrade Image/SDK Versions and Semantic Versioning","text":"<p>The HULKs use semantic versioning for the Yocto images and SDKs. This means that versions are increased depending on the severity of changes. The following policy exists for the HULKs:</p> <ul> <li>Both images and SDKs have major, minor, and patch version numbers (e.g. 4.2.3).</li> <li>Images and SDKs with the same major and minor version number are compatible with each other.</li> <li>Major changes, refactorings, or implementations result in the increase of the major version number.</li> <li>Minor changes, additions, and iterations result in the increase of the minor version number.</li> <li>Changes in the image that do not require SDK recreation, result in the increase of the patch version number. This consequently only requires creating a new image and not necessarily a redistribution of new SDKs.</li> </ul> <p>Before building new images, the version number needs to be set in <code>meta-nao/conf/distro/HULKsOS.conf</code>. Only change the <code>DISTRO_VERSION</code>, the <code>SDK_VERSION</code> is automatically derived from the <code>DISTRO_VERSION</code>.</p> <p>Once a new image and/or SDK is released, pepsi needs to know the new version numbers. Therefore update the variables <code>OS_VERSION</code> and/or <code>SDK_VERSION</code> in <code>crates/constants/src/lib.rs</code>. Successive builds with pepsi will use the new version.</p>"},{"location":"setup/nao_image_and_sdk/#upgrade-rust-version","title":"Upgrade Rust Version","text":"<p>Since upgrading the Rust version often requires manual steps, this section describes the approach on how to upgrade and generate the needed patch files. These instructions can be followed e.g. if a new Rust version is available and a new image/SDK should be created with this new version. Users that just want to use the current version that we upgraded to should skip this section.</p> <p>Rust is provided by the poky repository. The recipes are located in <code>meta/recipes-devtools/{cargo,rust}</code>. The following steps are high-level instructions on how to modify the poky repository. A patch file can be created after applying these instructions and saved to the corresponding meta-hulks layer.</p> <ul> <li>Set new version in the <code>RUSTVERSION</code> variable in <code>poky/meta/conf/distro/include/tcmode-default.inc</code></li> <li>Rename files (to new version) in <code>poky/meta/recipes-devtools/cargo/</code></li> <li>Rename files (to new version) in <code>poky/meta/recipes-devtools/rust/</code></li> <li>Some LLVM benchmarks are built and run during the compilation which often results in errors.     Therefore, it is a good idea to just exclude them by appending <code>-DLLVM_BUILD_BENCHMARKS=OFF</code> and <code>-DLLVM_INCLUDE_BENCHMARKS=OFF</code> to the <code>EXTRA_OECMAKE</code> variable in <code>poky/meta/recipes-devtools/rust/rust-llvm.inc</code>.</li> <li>Set new version in the <code>RS_VERSION</code> and <code>CARGO_VERSION</code> variable in <code>poky/meta/recipes-devtools/rust/rust-snapshot.inc</code></li> <li>Update the checksums in <code>poky/meta/recipes-devtools/rust/rust-snapshot.inc</code> for the NAO architecture <code>x86_64</code><ul> <li>Download the files in your command line (example for Rust version 1.63): <pre><code>RS_VERSION=\"1.63.0\"\nCARGO_VERSION=\"1.63.0\"\nRUST_BUILD_ARCH=\"x86_64\"\nRUST_STD_SNAPSHOT=\"rust-std-${RS_VERSION}-${RUST_BUILD_ARCH}-unknown-linux-gnu\"\nRUSTC_SNAPSHOT=\"rustc-${RS_VERSION}-${RUST_BUILD_ARCH}-unknown-linux-gnu\"\nCARGO_SNAPSHOT=\"cargo-${CARGO_VERSION}-${RUST_BUILD_ARCH}-unknown-linux-gnu\"\nwget \"https://static.rust-lang.org/dist/${RUST_STD_SNAPSHOT}.tar.xz\"\nwget \"https://static.rust-lang.org/dist/${RUSTC_SNAPSHOT}.tar.xz\"\nwget \"https://static.rust-lang.org/dist/${CARGO_SNAPSHOT}.tar.xz\"\n</code></pre></li> <li>Generate the checksums in the same terminal:     <pre><code>sha256sum ${RUST_STD_SNAPSHOT}.tar.xz ${RUSTC_SNAPSHOT}.tar.xz ${CARGO_SNAPSHOT}.tar.xz\n</code></pre></li> <li>Keep the terminal open for the next step</li> </ul> </li> <li>Update the checksums in <code>poky/meta/recipes-devtools/rust/rust-source.inc</code><ul> <li>Download the files:     <pre><code>wget \"https://static.rust-lang.org/dist/rustc-${RS_VERSION}-src.tar.xz\"\n</code></pre></li> <li>Generate the checksums in the same terminal:     <pre><code>sha256sum \"rustc-${RS_VERSION}-src.tar.xz\"\n</code></pre></li> </ul> </li> <li>Run <code>bitbake nao-image</code> within the build shell<ul> <li>Errors similar to <code>libstd-rs-1.63.0-r0 do_patch: Applying patch...</code> often mean that patches are obsolete.     These patches are located in <code>poky/meta/recipes-devtools/rust/libstd-rs/</code> and <code>poky/meta/recipes-devtools/rust/rust-llvm/</code>.     Deleted patches need to be removed from their corresponding recipes.     Afterwards rerun the image build.</li> </ul> </li> <li>Once a successful build completed, create a patch from the changes in poky:<ul> <li><code>sh     cd poky/     git add .     git commit # ...     git format-patch HEAD~  # this generates 0001-....patch</code></li> <li>Copy the patch file into <code>meta-nao/patches/0001....patch</code> and fix the patch path in <code>meta-nao/kas-project.yml</code></li> </ul> </li> </ul>"},{"location":"setup/nao_setup/","title":"NAO Setup","text":"<p>This section assumes you have a working development environment, and can successfully run <code>pepsi --help</code>. See Development Environment to learn how to setup your environment.</p> <p>Warning</p> <p>Make sure a RoboCupper image has been flashed before flashing the first Yocto image, since the latter does not flash the chestboard (which needs up-to-date firmware). This step is not required for flashing subsequent Yocto images.</p>"},{"location":"setup/nao_setup/#flashing-the-firmware","title":"Flashing the Firmware","text":"<p>You can flash the firmware both using pepsi or manually with a USB stick. Flashing with pepsi is the preferred option.</p>"},{"location":"setup/nao_setup/#using-pepsi-gammaray","title":"Using <code>pepsi gammaray</code>","text":"<p>Pepsi automatically downloads the latest configured release of the HULKs-OS image. To flash a robot use:</p> <pre><code>pepsi gammaray &lt;NAO&gt;\n</code></pre> <p>Where <code>&lt;NAO&gt;</code> is any configured NAO number or a full IP address.</p> Alternatively: Using an USB Stick"},{"location":"setup/nao_setup/#preparing-the-stick","title":"Preparing the Stick","text":"<p>First, the firmware image has to be written to the USB stick. Use <code>lsblk</code> to find the device that represents the USB stick.</p> <pre><code>lsblk\n</code></pre> <p>All existing data on the target device will be wiped! Replace <code>sdX</code> with the USB device.</p> <pre><code>dd if=path-to-nao-image.opn of=/dev/sdX status=progress\n</code></pre> <p>Finally, run <code>sync</code> to make sure all data has actually been written to the stick before unplugging it.</p> <pre><code>sync\n</code></pre>"},{"location":"setup/nao_setup/#flashing-the-nao","title":"Flashing the NAO","text":"<ul> <li>Make sure the robot is turned off and a charger is plugged in to prevent a sudden loss of power during the process.</li> <li>Plug the prepared USB stick into the back of the NAO's head.</li> <li>Hold the chest button for about 5 seconds until it starts glowing blue, then release immediately.   The chest button LED should now be flashing rapidly.</li> <li>Wait for the flashing process to finish</li> <li>The robot reboots at the end of the flashing process.</li> </ul>"},{"location":"setup/nao_setup/#checking-for-success","title":"Checking for success","text":"<p>When the flash process was successfull, the robot boots up and presents with red Knight Rider eyes. The new HULKs-OS is now installed and the NAO is waiting for the robotics software.</p>"},{"location":"setup/nao_setup/#remote-shell-access","title":"Remote Shell Access","text":"<p><code>./pepsi shell &lt;NAO&gt;</code> establishes an SSH connection and presents an interactive shell to the user.</p>"},{"location":"setup/overview/","title":"Overview","text":"<p>Todo</p> <p>High-Level visualization of the Software Architecture: NAO, SDK, HULKs-Robotics code, Pepsi, etc.</p> <p>This section describes the steps required to set up and get started with our framework. The following pages include documentation to</p> <ul> <li>setup the Development Environment,</li> <li>acquire or build the latest NAO operating system image and Software Development Toolkit (SDK) to cross-compile for the NAO,</li> <li>setup the NAO by flashing the operating system image to the NAO,</li> <li>and compile, upload, and run the HULKs robotics software on the robot</li> </ul>"},{"location":"setup/upload/","title":"Uploading HULK","text":"<p>This section assumes that you have set up your development environment and flashed a Yocto image to the NAO.</p> <p>Uploading the software to a NAO is done with Pepsi. See <code>pepsi --help</code> for details on the respective commands. To upload the robotics software to the NAO, just run:</p> <pre><code>pepsi upload &lt;NAO&gt;\n</code></pre> <p>Pepsi takes care of downloading and installing the SDK, calling <code>cargo</code> to trigger compilation, and uploading the software to the robot. When successful, you are presented with a green tick in your shell, and the robot is showing rotating rainbow eyes.</p>"},{"location":"setup/upload/#sdk-management","title":"SDK Management","text":"<p>Pepsi automatically checks for the latest SDK configured in the repository and installs it if necessary. To manually manage your SDK installation, use the <code>sdk</code> subcommand.</p> <pre><code>pepsi sdk install --help\n</code></pre>"},{"location":"tooling/aliveness/","title":"Aliveness","text":"<p>Aliveness is a system for querying status information from NAOs in the network. It consists of two parts: The service running on the NAOs and a client for sending aliveness requests to the network and processing answers.</p>"},{"location":"tooling/aliveness/#information-available-via-aliveness","title":"Information available via aliveness","text":"<p>The following information can be queried from NAOs connected via Ethernet:</p> <ul> <li>Hostname</li> <li>Current HULKs-OS version</li> <li>States of the systemd services for HAL, HuLA, HULK and LoLA</li> <li>Battery charge state and current</li> <li>Head ID</li> <li>Body ID</li> <li>Wireless network name</li> <li>Joint temperatures</li> <li>Name of the interface the beacon is received from (currently always enp4s0)</li> </ul>"},{"location":"tooling/aliveness/#aliveness-service","title":"Aliveness service","text":"<p>The aliveness service is built together with the HULKs-OS image and included in it. It is started upon the first connection with the network via Ethernet and listens for all messages send to the multicast address <code>224.0.0.42</code> as well as its own IP address.</p> <p>When receiving a UDP packet with content <code>BEACON</code>, it responds by sending the above described information encoded via JSON to the sender.</p>"},{"location":"tooling/aliveness/#aliveness-client","title":"Aliveness client","text":"<p>Pepsi includes a fully featured aliveness client with different verbosity levels and export options, see here for further information.</p> <p>Example usage:</p> <pre><code>./pepsi aliveness\n./pepsi aliveness 27 32\n./pepsi aliveness --json\n./pepsi aliveness --timeout 500 -v\n</code></pre> <p>When executing any of the aliveness subcommands in pepsi, it will send the aforementioned beacon message to the multicast address or to a list of NAO IP addresses. It then collects all responses within a timeout and filters their content according to the chosen verbosity level.</p>"},{"location":"tooling/aliveness/#potential-firewall-issues","title":"Potential firewall issues","text":"<p>When no NAO addresses are specified, the beacon is sent via multicast and the answers are received via unicast. Since the answers are from a different IP addresses, most firewalls may block them.</p> <p>In this case, the user has change their firewall settings to allow the incoming messages, e.g. for ufw by adding the following rule:</p> <pre><code>ufw allow proto udp from 10.1.24.0/24\n</code></pre>"},{"location":"tooling/overview/","title":"Overview","text":"<p>Apart from the NAO code our repository contains several tools to aid in the development and testing process:</p> <ul> <li>Pepsi: A multi-tool to automate repetitive tasks like compiling and deployment</li> <li>Twix: Our debugging tool to visualize live data from the NAO or a Webots simulation</li> <li>Depp: TODO: Irgendwas mit dependencies</li> <li>Fanta: TODO: Irgendwas mit live data auf der CLI</li> <li>Recording &amp; Replay: Post-mortem analysis of game data</li> <li>Machine Learning: Our tooling to create datasets and neural networks</li> <li>Behavior Simulator: The simulator and viewer to debug and automatically test behavior</li> <li>Debugging with GDB/LLDB: How to use a debugger with our software</li> </ul>"},{"location":"tooling/pepsi/","title":"Pepsi","text":"<p>Pepsi is a multi-tool we use for anything related to the code or the NAO robots. It can be used to build the code, set up configuration parameters for a game, deploy to a robot or simply open a remote shell.</p> <p>This page is only meant as a general overview of pepsi's subcommands. For detailed usage instructions, run <code>pepsi --help</code> or <code>pepsi &lt;subcommand&gt; --help</code>.</p>"},{"location":"tooling/pepsi/#typical-webots-workflow","title":"Typical Webots Workflow","text":"<p>This is pretty simple. Open Webots, load the <code>webots/worlds/penalized_extern.wbt</code> world file and execute</p> <pre><code>./pepsi run\n</code></pre> <p>in your terminal. This will build (if necessary) and then run the webots binary. The simulation is paused automatically until the binary starts.</p>"},{"location":"tooling/pepsi/#typical-nao-workflow","title":"Typical NAO Workflow","text":"<pre><code>./pepsi upload &lt;number or IP&gt;\n</code></pre> <p>This command does the following:</p> <ul> <li>checks if a toolchain is installed, downloads, and installs one if necessary</li> <li>builds the code for the NAO target</li> <li>uploads binary, configuration parameters, motion files, neural networks, etc. to the NAO(s)</li> <li>restarts HULK service on the NAO(s)</li> </ul>"},{"location":"tooling/pepsi/#interaction-with-the-nao","title":"Interaction with the NAO","text":"<p>NAOs are identified either by IP or by number. Numbers are converted to IPs as follows:</p> <ul> <li><code>{number}</code> -&gt; <code>10.1.24.{number}</code></li> <li><code>{number}w</code> -&gt; <code>10.0.24.{number}</code></li> </ul> <p>Many subcommands can act on multiple robots concurrently.</p> <p><code>upload</code> builds a binary for the NAO target, and then uploads it and parameter files to one or more robot.</p> <p><code>wireless</code>, <code>reboot</code>, <code>poweroff</code>, and <code>hulk</code> directly interact with the robot(s), whereas <code>communication</code>, and <code>playernumber</code> only change the local configuration parameters.</p> <p><code>pregame</code> combines deactivating communication (to avoid sending illegal messages), assigning playernumbers, setting a wifi network, uploading, and restarting the HULK service.</p> <p><code>logs</code> or and <code>postgame</code> can be used after a (test-)game to download logs, the latter also shuts down the HULKs binary and disables wifi.</p> <p><code>gammaray</code> is used for flashing a HULKs-OS image to one or more robots.</p>"},{"location":"tooling/pepsi/#build-options","title":"Build Options","text":"<p>For subcommands that build a binary, you can specify a target and a build profile. These include <code>build</code>, <code>run</code>, <code>check</code>, and <code>clippy</code>. However <code>upload</code> and <code>pregame</code> only supports a profiles, since it doesn't make sense to upload a webots binary to the nao.</p>"},{"location":"tooling/pepsi/#aliveness","title":"Aliveness","text":"<p>Using the <code>aliveness</code> subcommand, pepsi can query information from NAOs connected via ethernet. By default, only irregular information like non-active services, outdated HULKs-OS versions and battery charge levels below 95% are displayed. Using <code>-v</code>/<code>--verbose</code> or <code>-j</code>/<code>--json</code>, you can retrieve all information available via aliveness in either a human- or machine-readable format.</p> <p>You can also set a timeout via <code>-t</code>/<code>--timeout</code> (defaulting to 200ms) and specify NAO addresses (e.g. <code>22</code> or <code>10.1.24.22</code>) for querying the aliveness information only from specific NAOs.</p> <p>Further information on the information available via aliveness as well as the details to the protocol can be found here.</p>"},{"location":"tooling/pepsi/#shell-completion","title":"Shell Completion","text":"<p>Shell completions can be generated using the <code>completions</code> subcommand.</p> <p>Example:</p> <pre><code>./pepsi completions zsh &gt; _pepsi\n</code></pre> <p>Refer to your shell's completion documentation for details.</p> <p>The shells completions for fish, zsh and bash include dynamic suggestions for all pepsi subcommands taking a NAO address as an argument (e.g. <code>pepsi upload</code>). Those suggestions are retrieved using the aliveness service and require a version of pepsi to be installed in the <code>PATH</code>, e.g. by using</p> <pre><code>cargo install --path tools/pepsi\n</code></pre> <p>and adding <code>~/.cargo/bin</code> to the <code>PATH</code>.</p>"},{"location":"tooling/pepsi/#remote-compile","title":"Remote Compile","text":"<p>To use the remote compilation you need to create an account on the remote-compiler. Open an ssh connection to <code>root@134.28.57.226</code>. There create a new account by <code>adduser {name}</code> and set a password with <code>passwd {name}</code>.</p> <p>Terminate the root ssh session and log in with your new user <code>{name}@134.28.57.226</code>. There clone the HULKs repository using https: <code>https://github.com/HULKs/hulk.git</code></p> <p>Back on your local machine do <code>ssh-copy-id {name}@134.28.57.226</code> to allow passwordless login. In the hulk repo, create a <code>.REMOTE_WORKSPACE</code> file containing the username, IP, and path, e.g. <code>{name}@134.28.57.226:hulk</code>.</p> <p>Now you can use the pepsi remote features:</p> <pre><code>./pepsi build --remote\n</code></pre> <p>This will sync your local files to the remote, run the build command there, and then return the final binary to you. Other pepsi commands such as <code>run</code>, <code>upload</code>, or <code>pregame</code> also have a <code>--remote</code> option.</p> <p>To use the remote compile functionality from outside the lab, you need a VPN connection. Ask one of the older team members to provide you a <code>.ovpn</code> file. Create a new VPN client with this configuration file. This allows you to use the remote compiler, however it is not possible to upload to the robots from the VPN. To solve this, you can either delete the routes to the robots, e.g. using <pre><code>ip route delete 10.1.24.0/24 via 10.2.24.1 dev tun0\n</code></pre> or manually configure the routes of the VPN. In gnome-settings, this looks like the following </p>"},{"location":"tooling/recording_and_replay/","title":"Recording and Replay","text":"<p>The framework supports to record the robots data and replay it afterwards for easy analysis. For each cycler instance, only the node states and inputs at the beginning of each cycle are recorded. During replay, the inputs and node states are used to recompute all outputs. A started communication server during replay can be used to investigate the recorded data via, e.g., Twix.</p>"},{"location":"tooling/recording_and_replay/#record","title":"Record","text":"<ul> <li>Manual upload to a robot<ul> <li>Use <code>./pepsi recording ...</code> to enable recording at different recording rates, e.g., <code>./pepsi recording Control=1,VisionTop=30</code><ul> <li>This will set the cycler instances and recording rate in <code>etc/parameters/framework.json</code></li> </ul> </li> <li>Use <code>./pepsi upload ...</code> to upload as usual (this includes the framework configuration with the cycler instances)</li> </ul> </li> <li>Pregame<ul> <li>Use <code>./pepsi pregame --recording-intervals ... ...</code> to enable recording at different recording rates and upload to the robot in one step, e.g., <code>./pepsi pregame --recording-intervals Control=1,VisionTop=30 ...</code><ul> <li>This will set and overwrite the recording intervals in <code>etc/parameters/framework.json</code></li> </ul> </li> </ul> </li> </ul> <p>Be careful enabling vision cyclers because this will result in a lot of data being recorded. Top and bottom vision cyclers may fill the entire disk within approximately 10 minutes.</p> <p>Data is only recorded during <code>PrimaryState::Ready</code>, <code>PrimaryState::Set</code>, and <code>PrimaryState::Play</code>.</p>"},{"location":"tooling/recording_and_replay/#replayer","title":"Replay(er)","text":"<p>Assuming you already recorded some data on a robot, you can now use the \"replayer\" tool to replay the recorded data.</p> <ul> <li>Download the logs into a <code>logs</code> directory within the repository via, e.g., <code>./pepsi postgame ... my_awesome_replay ...</code></li> <li>The <code>my_awesome_replay</code> directory now contains directories for each robot. Each robot directory contains one directory with the replay data from one execution of the <code>hulk</code> binary.   All cycler instance files need to be present, regardless whether they were enabled during recording (they will be empty then).</li> <li>Start the replayer tool by pointing it to the log directory you want to replay, e.g., <code>./pepsi run --target replayer -- my_awesome_replay/10.1.24.42/12345678</code>.</li> <li>Connect your Twix to <code>localhost</code> and open some panels</li> <li>Use mouse and keyboard in replayer, as described below</li> <li>...</li> <li>Profit</li> </ul>"},{"location":"tooling/recording_and_replay/#mouse-and-keyboard-controls","title":"Mouse and Keyboard Controls","text":"<ul> <li>Mouse dragging: Move the current replay time position (green bar)</li> <li>Horizontal scrolling: Panning in time domain</li> <li>Vertical scrolling: Zooming in time domain</li> <li>Horizontal scrolling with pressed Shift key: Panning in time domain</li> <li>Pressing J or down arrow key: jump 10 seconds backward</li> <li>Pressing L or up arrow key: jump 10 seconds forward</li> <li>Pressing left arrow key: jump 1 second backward</li> <li>Pressing right arrow key: jump 1 second forward</li> <li>Pressing comma key: jump 10 milliseconds backward</li> <li>Pressing dot key: jump 10 milliseconds forward</li> </ul>"},{"location":"tooling/recording_and_replay/#image-extraction","title":"Image extraction","text":"<p>To extract images from recording data, you can use the \"imagine\" tool.</p> <p>Example: <pre><code>./pepsi run --target imagine -- my_awesome_replay/10.1.24.42/12345678 path/to/output\n</code></pre></p>"},{"location":"workflow/competition/","title":"Competition","text":"<p>TODO</p>"},{"location":"workflow/competition/#meetings","title":"Meetings","text":"<p>TODO</p>"},{"location":"workflow/competition/#roles","title":"Roles","text":"<p>TODO</p>"},{"location":"workflow/development/","title":"Development","text":"<p>TODO</p>"},{"location":"workflow/development/#github","title":"GitHub","text":"<p>TODO</p>"},{"location":"workflow/development/#ci","title":"CI","text":"<p>TODO</p>"},{"location":"workflow/development/#the-development-project","title":"The Development Project","text":"<p>At HULKs we use a quite heavily modified version of the KanBan workflow. The Current Boards purpose is to visualize our current development status. The modifications were mainly done to address the fact that we do not have fixed working hours. Limiting the amount of cards that are in progress does not work. Especially for members that are not present on a daily basis. The List is mainly for organizing multiple iterations for a more long-term overview (important for dev-leads).</p>"},{"location":"workflow/development/#terms","title":"Terms","text":"<p>Assignee: The person that is responsible for a card (has the exclusive right to move a card(!) as soon as there is one). The assignee's job depends on the Kanban column:</p> <ul> <li>No assignee: Open, Done</li> <li>Assignee works on issue/pull request (if more or less progress happens on it): In Progress</li> <li>Assignee is responsible to bring a pull request to <code>main</code> (e.g. reviewer, tester): Request for Review</li> </ul> <p>Note that github distinguishes between reviewers and assignees. We also do that. Kind of. While the assignee (in most cases one person) is responsible for the card and bring the branch into the main, the reviewer(s) (can be more than one) can review the code at any time in addition to the notes that were given by the assignee. In general: The more reviewers the better the resulting code (That being said: feel free to review code).</p> Open In Progress Request for Review Done -------- Developer Reviewer -------- <p>Author: The person that created this card (issue/pull request). Responsible for answering questions (issues/pull requests) and implement/discuss requested changes (pull requests).</p>"},{"location":"workflow/development/#open","title":"Open","text":"<p>The Open section contains by the dev-leads selected issues that are important and of high priority for the current iteration. However, if you want to work on issues that are not in Open: Feel free to do so.</p> <p>Move (or add) an issue into In Progress and assign yourself when you started working on it.</p>"},{"location":"workflow/development/#in-progress","title":"In Progress","text":"<p>The In Progress section contains:</p> <ul> <li>issues that have an assignee, but no open pull request. As soon as there is an open pull request fixing this issue, the issue card should be replaced by this pull request card (removing the Issue from the Project but not closing it as it is not fixed in the main yet). The issue must then be mentioned with the <code>fixes #Issue_NO</code> in the pull requests description.</li> <li>pull requests that are not ready for review yet and are currently wip.</li> </ul> <p>Note: <code>fixes #Issue_NO</code> is a keyword on github. Github will automatically close the mentioned issue whenever the corresponding pull request was merged. Do not close issues that have not being fixed in the main yet (even if there is a pull request for it)!</p> <p>Move a pull request into Request for Review when you have finished your work and tested the pull request yourself on relevant platforms. At this stage a pull requests' description should be finalized (fill out the template properly).</p>"},{"location":"workflow/development/#request-for-review","title":"Request for Review","text":"<p>The Request for Review section contains pull requests that are ready to be reviewed. They don't need to be finished\u2122 for that, they can still be a draft pull request.</p> <p>Note: This section is a prioritized FIFO queue. Add new cards at the bottom. The head of development might decide to move it further up if the pull request is rather important.</p> <p>Note: Enable auto-merge if your pull request is not a draft pull request</p> <p>Assign yourself if you want to review this pull request.</p> <p>Conversation-Resolve-Policy: The person (the reviewer) who opened a conversation is the only one allowed to resolve it. The reviewer and author may use this policy to see which feedback has not been addressed yet.</p>"},{"location":"workflow/development/#meetings","title":"Meetings","text":"<p>We have a recurring Dev-Meeting every Wednesday, where we discuss all matters related to our development progress.</p>"},{"location":"workflow/development/#test-games","title":"Test Games","text":"<p>We regulary test our codebase in test games, usually after our Dev-Meeting</p>"},{"location":"workflow/development/#test-driven-development","title":"Test-driven development","text":"<p>TODO</p>"},{"location":"workflow/development/#unit-testing","title":"Unit testing","text":"<p>TODO</p>"},{"location":"workflow/development/#webots","title":"Webots","text":"<p>TODO</p>"},{"location":"workflow/development/#behavior-simulator","title":"Behavior Simulator","text":"<p>TODO</p>"},{"location":"workflow/engineering/","title":"Engineering","text":"<p>Team HULKs wants to sustain high quality and correct software for playing soccer at RoboCup. This requires common software engineering skills that are briefly covered on this page. Each feature that lands in the software in the end has a purpose and should fulfill the purpose well. The purpose is described with requirements which allow to design a solution that meets the requirements. The solution can later be implemented, tested, and integrated into the software.</p> <p>The section \"Tasks in large scale projects\" gives a rough outline over the software engineering duties. Team HULKs is interpreting this in the following ways:</p> <ul> <li>Requirements:<ul> <li>What problem do you want to solve?</li> <li>Is that problem worth solving? Cost vs. benefit, measure to acquire facts</li> <li>What is required?</li> <li>What is not required?</li> </ul> </li> <li>Design:<ul> <li>What components need to be touched/created?</li> <li>What properties have the components?</li> <li>What properties need to be added/modified/removed?</li> <li>How do the components interact?</li> <li>What data structures and algorithms should be used?</li> <li>What is the implementation plan?</li> <li>How can this design be tested?</li> </ul> </li> <li>Construction:<ul> <li>Design is implemented</li> <li>Tests are written during development to ensure correctness</li> <li>Measure</li> </ul> </li> <li>Evaluation:<ul> <li>Are the requirements fulfilled?</li> </ul> </li> </ul> <p>Each phase ends with a review of the artifacts, by a non-author.</p>"},{"location":"workflow/getting_started/","title":"Getting Started Programming at HULKs","text":"<p>Please follow the instructions given in Setup to setup <code>rust</code> on your machine. The tool used for compiling, uploading or changing the robot state otherwise is called <code>pepsi</code>. Another tool often used to debug on the robot is called <code>twix</code>. With <code>twix</code> you can connect to a robot and inspect the output of nodes.</p>"},{"location":"workflow/getting_started/#starting-development","title":"Starting Development","text":""},{"location":"workflow/getting_started/#setting-up-git","title":"Setting up Git","text":"<p>Head into your webbrowser and fork the repository. This will add a copy of the hulks repository under your user. All development should happen on your personal fork of the project and should be brought into the hulks repository only using pull requests. When you have created a fork, head into the cloned hulks repository. When typing</p> <pre><code>git remote -v\n</code></pre> <p>all your currently configured remotes will be shown.</p> <pre><code>origin  git@github.com:HULKs/hulk.git (fetch)\norigin  git@github.com:HULKs/hulk.git (push)\n</code></pre> <p>You can add your fork as a remote by running </p> <pre><code>git remote add &lt;NAME&gt; &lt;FORK_LINK&gt;\n</code></pre> <p>and substituting <code>&lt;NAME&gt;</code> with a suitable name for your fork and fork link with the link of your git repo. If you list your remotes again, it should now look similar to this:</p> <pre><code>origin  git@github.com:HULKs/hulk.git (fetch)\norigin  git@github.com:HULKs/hulk.git (push)\nokiwi6  git@github.com:okiwi6/hulk.git (fetch)\nokiwi6  git@github.com:okiwi6/hulk.git (push)\n</code></pre> <p>Of course instead of <code>okiwi6</code>, your name should appear there \ud83d\ude09. If you like, you can rename the <code>origin</code> remote to something more descriptive, for example <code>git remote rename origin hulk</code> to name it <code>hulk</code>.</p>"},{"location":"workflow/getting_started/#creating-a-branch","title":"Creating a Branch","text":"<p>When running <code>git status</code>, you'll most likely see that you are on the <code>main</code> branch of the repository.</p> <pre><code>On branch main\nYour branch is up to date with 'origin/main'.\n\nnothing to commit, working tree clean\n</code></pre> <p>To create a new feature branch, run <code>git switch -c &lt;branch_name&gt;</code>. Here you can start developing your feature.</p>"},{"location":"workflow/getting_started/#developing","title":"Developing","text":"<p>For a overview of the current robotics code, check out this overview. If you don't have a task already, have a look at our development board or ask one of our Dev-Leads. An introduction to how our project management works, can be found here</p>"},{"location":"workflow/getting_started/#commiting","title":"Commiting","text":"<p>Commiting is a crucial Git action, that allows to set \"checkpoints\" of your work. It is possible to jump between different commits or include them in other branches. Therefore it is important that you commit frequently. Optimally the code should be in a compilable state whenever you commit.</p> <p>In order to commit, you first have to add your changes to the staging area. This can be done easily in Visual Studio Code using the <code>Source Control</code> side bar and hitting <code>+</code> on the correct files. Alternatively, you can run <code>git status</code> in the hulks repository to see all changes. Then you can add files manually using the <code>git add &lt;path_to_file&gt;</code> command. To commit all changes listed in your staging area, in Visual Studio Code you can use the <code>Source Control</code> panel again. Create a suitable commit message and then hit the green commit button. In the terminal the equivalent action is <code>git commit</code>, which will open a text editor for your commit message (Alternatively, run <code>git commit -m\"&lt;your_commit_message&gt;\"</code>) to avoid entering a text editor). Commit messages should be short and descriptive.</p> <p>You can inspect your commit history by running <code>git log --oneline</code>, this will produce something similar to this</p> <pre><code>b356357ba Add nixgl as dependency\n4de357b34 Add nix development shell via flake\nbb072fd4b Add approx_derive\n9951fcd6c Update hula lock file\n73449edd0 Add non-workspace lock files to check\n...\n</code></pre>"},{"location":"workflow/getting_started/#pushing","title":"Pushing","text":"<p>To push to your remote, run <code>git push &lt;remote_name&gt;</code>. You can also configure remotes of other team mates and push to their fork, given they add you as a collaborator with write access to their fork.</p>"},{"location":"workflow/getting_started/#creating-a-pull-request","title":"Creating a Pull Request","text":"<p>Head to the HULKs Repository Pull Requests section. There you can click <code>New pull request</code>, then click <code>compare across forks</code>.</p> <p>Select your fork and branch to merge into <code>hulk/main</code>.</p> <p>Then fill out the given markdown template. Please be as descriptive as possible, since other people need to understand what you did. By adding a issue number behind the <code>Fixes #</code> line, you can automatically link an issue that gets closed when your PR is merged.</p> <p>Then create the pull request.</p> <p>After that assign corresponding labels and select the <code>Development</code> Project and <code>Request for Review</code>.</p> <p>After creating your PR, our CI will start running. If it generates findings, you need to fix the issues on your branch and push again.</p>"},{"location":"workflow/github_webhooks/","title":"GitHub Webhooks","text":"<p>The HULKs use HULKs/GitHubNotificationsBot for GitHub notifications in their messengers. Since we open-sourced our main repository, we do not have permissions to register webhooks in forks of the repository. This page serves a guide on how to setup and enable GitHub notifications from your repository.</p>"},{"location":"workflow/github_webhooks/#register-new-webhook","title":"Register New Webhook","text":"<ol> <li>In your forked repository, go to Settings, Webhooks, Add webhook</li> <li>Payload URL is <code>https://github-notifications.hulks.dev/</code></li> <li>Content type is <code>application/json</code></li> <li>Ask one of our Dev-Leads for the secret</li> <li>Leave SSL verification on</li> <li>Select \"Let me select individual events\" and enable the following:<ul> <li>Issue comments</li> <li>Issues</li> <li>Pull request review comments</li> <li>Pull request reviews</li> <li>Pull requests</li> <li>Pushes</li> </ul> </li> <li>Activate it and add it</li> <li>Profit</li> </ol>"},{"location":"workflow/github_webhooks/#adminstration-of-the-bot","title":"Adminstration of the Bot","text":"<p>The bot is running on the HULKs Nextcloud VM (RZ) machine. The address can be found the IP Address Range wiki page of the HULKsnition repository. A VPN connection is required to connect via SSH. The Docker Compose directory is located at <code>/mnt/ext/docker-config/web/</code> and the service is named <code>github-notifications</code>.</p>"},{"location":"workflow/leadership/","title":"Leadership","text":"<p>The goal of the team HULKs is to compete with other teams in the RoboCup Standard Platform League (SPL). Being competitive on such events with mostly part-time participating students requires optimal team performance and a focused development workflow to achieve set goals. Two members of the HULKs manage and lead the team towards the goals. These members are called development leads. Beside participating in normal development activities, development leads act by representing multiple roles where each has responsibilities.</p>"},{"location":"workflow/leadership/#roles-and-responsibilities","title":"Roles and Responsibilities","text":"<p>The following roles exist at the HULKs which craft the development leads.</p>"},{"location":"workflow/leadership/#technology-lead","title":"Technology Lead","text":"<p>Is responsible for technical specifications, architecture and its enforcement, and other technical areas.</p> <p>It identifies and fixes technical problems, consults the team or experts to acquire relevant information and makes decisions. Knowledge and guidance is given via pairing, code reviews, or meetings.</p>"},{"location":"workflow/leadership/#people-lead","title":"People Lead","text":"<p>Is responsible for enabling the team members to efficiently work with each other.</p> <p>It knows about interests, current activities, good and bad feelings of the team members. The people lead establishes a constructive and open feedback culture in the team but may also forward feedback between team members and honor good performances publicly. It supports building fitting groups, carefully breaks up unfitting groups, and manages group sizes. It may moderate within groups and connects multiple related groups together.</p>"},{"location":"workflow/leadership/#team-lead","title":"Team Lead","text":"<p>Is responsible for enabling the team to work on the set goals.</p> <p>It defines the development workflows, provides instructions and documentation, and monitors the team performance to derive improvements of the former. The team lead compares the required skills with the available skills of the team members and proposes ways to upskill. It connects newbies with experts and organizes/supervises team events and hackathons. It mentors newbies and supervises onboarding to technical topics. It ensures the propagation of our values, spirit, and quality demands to all team members. It engages that team members help and take over club activities.</p>"},{"location":"workflow/leadership/#recruiting-lead","title":"Recruiting Lead","text":"<p>Is responsible that the team remains to exist in the future.</p> <p>It ensures that the team regularly and strategically recruits new members. It actively takes part in the recruiting efforts and motivates other existing members to join the activities. The recruiting lead acts as the first-level contact person for new recruits, communicates with them, and encourages them to join the HULKs club. It actively reminds (not only) recruits to come to sign the club registration form and join our club activities, i.e., join meetings, being present in the lab, participate in organization and development activities.</p>"},{"location":"workflow/leadership/#project-management","title":"Project Management","text":"<p>Is responsible that the team achieves the set goals.</p> <p>It defines and prioritizes the goals aligned with the RoboCup rules that the team tries to achieve. The project management communicates the goals and ensures that each team member works towards their achievement within defined deadlines. It provides tasks that are derived from the goals and makes these tasks, together with a time plan, available to the team. It ensures and supports that the team makes progress on the tasks and helps to break them down into sub-tasks. It monitors work on the tasks, reminds to focus on essentials, notices blocked tasks and supports to unblock them, e.g., by connecting with experts or scheduling discussions in the team.</p>"},{"location":"workflow/overview/","title":"Overview","text":"<p>TODO: Elaborate</p> <ul> <li>Development workflow<ul> <li>GitHub<ul> <li>CI</li> <li>Board</li> </ul> </li> <li>Meetings<ul> <li>Test games</li> </ul> </li> <li>Test-driven development<ul> <li>Unit testing</li> <li>Webots</li> <li>Behavior Simulator</li> </ul> </li> </ul> </li> <li>Competition workflow<ul> <li>Meetings</li> <li>Roles</li> </ul> </li> </ul>"}]}